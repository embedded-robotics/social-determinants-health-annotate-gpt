{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f905e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd63b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d04df0",
   "metadata": {},
   "source": [
    "## Extract Data into Accepted Format\n",
    "### Unnanotated DataFrame Necessary Columns:\n",
    "- <b>ID</b> Unique identifier number for ease of reference\n",
    "- <b>TEXT</b> This column should hold all relevant text that should be annotated by AnnotateGPT\n",
    "\n",
    "##### Example Unnanotated Sample\n",
    "<table>\n",
    "  <tr>\n",
    "    <th><center>ROW_ID</center></th>\n",
    "    <th><center>TEXT</center></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><center>1</center></td>\n",
    "    <td><center>Patient...</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><center>...</center></td>\n",
    "    <td><center>...</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><center>2038</center></td>\n",
    "    <td><center>The patient comes from...</center></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "### Unnanotated DataFrame Necessary Columns:\n",
    "- <b>ID</b> Unique identifier number for ease of reference\n",
    "- <b>TEXT</b> This column should hold all relevant text that should be annotated by AnnotateGPT\n",
    "- <b>LABEL NAME</b> This column should hold the categorization for the label in question. There may be more than one <i>LABEL NAME</i> column, and each should have its own unique name.\n",
    "\n",
    "##### Example Annotated Sample\n",
    "<table>\n",
    "  <tr>\n",
    "    <th><center>ROW_ID</center></th>\n",
    "    <th><center>TEXT</center></th>\n",
    "    <th><center>sdoh_community_present</center></th>\n",
    "    <th><center>sdoh_economics</center></th>\n",
    "    <th><center>behavior_tobacco</center></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th><center>1</center></th>\n",
    "    <td><center>The patient...</center></td>\n",
    "    <td><center>1</center></td>\n",
    "    <td><center>0</center></td>\n",
    "    <td><center>1</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><center>...</center></td>\n",
    "    <td><center>...</center></td>\n",
    "    <td><center>...</center></td>\n",
    "    <td><center>...</center></td>\n",
    "    <td><center>...</center></td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td><center>233</center></td>\n",
    "    <td><center>Patient's family...</center></td>\n",
    "    <td><center>1</center></td>\n",
    "    <td><center>0</center></td>\n",
    "    <td><center>0</center></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "### Example Extraction of MIMIC-III and MIMIC-SBDH Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_ID_COLUMN_NAME = \"ROW_ID\"\n",
    "UNIQUE_TEXT_COLUMN_NAME = \"TEXT\"\n",
    "UNIQUE_LABEL_COLUMN_NAMES = ['sdoh_community_present','sdoh_economics','behavior_tobacco']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8cc84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_social_history(df):\n",
    "    replace_texts = []\n",
    "    for row_id in df[UNIQUE_ID_COLUMN_NAME]:\n",
    "        patient = df[df[UNIQUE_ID_COLUMN_NAME] == row_id][UNIQUE_TEXT_COLUMN_NAME].iloc[0]\n",
    "        social_history_start = patient.lower().find('social history:')\n",
    "        pos_ends = []\n",
    "        pos_ends.append(patient.lower().find('family history:'))\n",
    "        pos_ends.append(patient.lower().find('physical exam'))\n",
    "        pos_ends.append(patient.lower().find('medications:'))\n",
    "        pos_ends.append(patient.lower().find('hospital course:'))\n",
    "        pos_ends.append(patient.lower().find('review of systems:'))\n",
    "        pos_ends = [x for x in pos_ends if x > social_history_start]\n",
    "        pos_ends.append(social_history_start+500)\n",
    "        social_history_end = min(pos_ends)\n",
    "        replace_texts.append((row_id,patient[social_history_start:social_history_end]))\n",
    "    texts = pd.DataFrame(replace_texts,columns =[UNIQUE_ID_COLUMN_NAME,UNIQUE_TEXT_COLUMN_NAME])\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e7517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths to MIMIC_CSVs\n",
    "MIMIC_ADMISSION_CSV = \"ADMISSIONS.csv\" #Fill in path/to/file with the path to your MIMIC-III folder\n",
    "MIMIC_NOTEEVENTS_CSV = \"NOTEEVENTS.csv\" #Fill in path/to/file with the path to your MIMIC-III folder\n",
    "MIMIC_SBDH = \"MIMIC-SBDH.csv\" #Fill in path/to/file with the path to your MIMIC-SBDH folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading DataFrames for Annotated and Unnanotated MIMIC Notes\n",
    "\n",
    "df = pd.read_csv(MIMIC_ADMISSION_CSV)\n",
    "newborn_list = df[df[\"ADMISSION_TYPE\"] == \"NEWBORN\"].SUBJECT_ID.to_list()\n",
    "notes_df = pd.read_csv(MIMIC_NOTEEVENTS_CSV)\n",
    "discharge_df = notes_df[notes_df['CATEGORY'] == 'Discharge summary']\n",
    "non_neonatal = discharge_df[~discharge_df['SUBJECT_ID'].isin(newborn_list)]\n",
    "sbdh_data = pd.read_csv(open(MIMIC_SBDH, 'r+', encoding='UTF-8'),encoding='UTF-8', on_bad_lines='warn')\n",
    "sbdh_data = sbdh_data.rename(columns={'row_id':UNIQUE_ID_COLUMN_NAME})\n",
    "annotated_list = sbdh_data[UNIQUE_ID_COLUMN_NAME].tolist()\n",
    "annotated_notes = discharge_df[discharge_df[UNIQUE_ID_COLUMN_NAME].isin(annotated_list)]\n",
    "annotated_subjects = discharge_df[discharge_df[UNIQUE_ID_COLUMN_NAME].isin(annotated_list)].SUBJECT_ID.to_list()\n",
    "\n",
    "no_soc_his = []\n",
    "for index, row in non_neonatal.iterrows():\n",
    "    if 'social history:' not in row[UNIQUE_TEXT_COLUMN_NAME].lower():\n",
    "        no_soc_his.append(row[UNIQUE_ID_COLUMN_NAME])\n",
    "\n",
    "final_sdoh_list = non_neonatal[~non_neonatal[UNIQUE_ID_COLUMN_NAME].isin(no_soc_his)]\n",
    "unnanotated_notes = final_sdoh_list[~final_sdoh_list[UNIQUE_ID_COLUMN_NAME].isin(annotated_list)]\n",
    "\n",
    "annotated_sh = retrieve_social_history(annotated_notes)\n",
    "annotated_sh = pd.merge(annotated_sh,sbdh_data[[UNIQUE_ID_COLUMN_NAME] + UNIQUE_LABEL_COLUMN_NAMES],on=UNIQUE_ID_COLUMN_NAME, how='left')\n",
    "unannotated_sh = retrieve_social_history(unnanotated_notes)\n",
    "\n",
    "df = newborn_list = notes_df = discharge_df = non_neonatal = annotated_list = annotated_subjects = no_soc_his = final_sdoh_list = unnanotated = sbdh_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95caafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "economics_binary = [1 if x == 2 else 0 for x in annotated_sh.sdoh_economics.to_list()]\n",
    "tobacco_binary = [1 if x == 1 or x == 2 else 0 for x in annotated_sh.behavior_tobacco.to_list()]\n",
    "annotated_sh = annotated_sh.drop(columns=['sdoh_economics','behavior_tobacco'])\n",
    "annotated_sh['sdoh_economics'] = economics_binary\n",
    "annotated_sh['behavior_tobacco'] = tobacco_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886327d4",
   "metadata": {},
   "source": [
    "## Example XGBoost setup for MIMIC tasks\n",
    "Select one of the 3 MIMIC tasks available. Change the variable associated with the task to True for the desired task. You need to place “XX-XX-gpt-train.pkl” files created using the <b>AnnotateGPT - SHARECOPY</b> file in their appropriate subfolder in the <b>SBDH-Annotated-Sets</b> folder if you wish to train using AnnotateGPT training sets. Pre-annotated Community AnnotateGPT training sets have been provided as a demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a MIMIC task. Only one must be true, two must be false. \n",
    "# Default: community\n",
    "community = True\n",
    "economics = False\n",
    "tobacco = False\n",
    "\n",
    "assert community + economics + tobacco == 1, \"One and only one must be True, the other two must be False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if community:\n",
    "    task = 'community'\n",
    "    label_column = \"sdoh_community_present\"\n",
    "elif economics:\n",
    "    task = 'economics'\n",
    "    label_column = \"sdoh_economics\"\n",
    "else:\n",
    "    task = 'tobacco'\n",
    "    label_column = \"behavior_tobacco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4731114",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_sets = [f for f in os.listdir(f'./SBDH-Annotated-Sets/{task}/') if '.pkl' in f]\n",
    "TRAINSETS = [x for x in annotated_sets if 'test' not in x]\n",
    "TESTSET = list(set(TRAINSETS).symmetric_difference(set(annotated_sets)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_best_threshold(predictions, true_labels):\n",
    "    \n",
    "    tpr, fpr, thresholds = roc_curve(true_labels, [n[1] for n in predictions])\n",
    "    auroc = auc(tpr, fpr)\n",
    "    \n",
    "    class_preds = [1 if (x > 0.5) else 0 for x in [n[1] for n in predictions]]\n",
    "    cm = confusion_matrix(true_labels, class_preds)\n",
    "    target_names = ['negative', 'positive']\n",
    "    clss_report = classification_report(true_labels, class_preds, target_names=target_names,digits=4)\n",
    "    \n",
    "    return {'clss_report':clss_report, 'auroc':auroc, 'confusion_matrix':cm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec316eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_better(text):\n",
    "    # tokenize the text by replacing punctuation and numbers with spaces and lowercase all words\n",
    "    punc_list = string.punctuation+'0123456789'\n",
    "    t = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
    "    text = text.lower().translate(t)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72357153",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_metrics = []\n",
    "\n",
    "for trainset in TRAINSETS:\n",
    "    train_example = pickle.load(open(f'./SBDH-Annotated-Sets/{task}/{trainset}','rb'))\n",
    "    train_id_list = train_example[UNIQUE_ID_COLUMN_NAME].to_list()\n",
    "    if all(x in unannotated_sh[UNIQUE_ID_COLUMN_NAME].to_list() for x in train_id_list):\n",
    "        master_df = unannotated_sh\n",
    "        training_df = master_df[master_df[UNIQUE_ID_COLUMN_NAME].isin(train_id_list)]\n",
    "        training_df = pd.merge(training_df,train_example[[UNIQUE_ID_COLUMN_NAME, 'sdoh_community_present']],on=UNIQUE_ID_COLUMN_NAME, how='left')\n",
    "\n",
    "    elif all(x in annotated_sh[UNIQUE_ID_COLUMN_NAME].to_list() for x in train_id_list):\n",
    "        master_df = annotated_sh\n",
    "        training_df = master_df[master_df[UNIQUE_ID_COLUMN_NAME].isin(train_id_list)]\n",
    "    else:\n",
    "        raise Exception(\"Incorrect training sample list, cannot continue\")\n",
    "    \n",
    "    test_df = pickle.load(open(f'./SBDH-Annotated-Sets/{task}/{TESTSET}','rb'))\n",
    "    test_df = annotated_sh[annotated_sh[UNIQUE_ID_COLUMN_NAME].isin(test_df[UNIQUE_ID_COLUMN_NAME].to_list())]\n",
    "    \n",
    "    EXAMPLE_LIST = [16,32,64,128,256,512,1024,2048]\n",
    "    \n",
    "    my_stop_words = stopwords.words('english')\n",
    "    \n",
    "    full_metrics = []\n",
    "    for EXAMPLES in EXAMPLE_LIST:\n",
    "        example_train = pd.concat([training_df[training_df[label_column] == 0].sample(n=int(EXAMPLES/2)),\n",
    "                                   training_df[training_df[label_column] == 1].sample(n=int(EXAMPLES/2))])\n",
    "\n",
    "        vect = CountVectorizer(max_features = 3000, \n",
    "                           tokenizer = tokenizer_better, \n",
    "                           stop_words = my_stop_words)\n",
    "        vect.fit(example_train.TEXT.values)\n",
    "\n",
    "        train_vect = vect.transform(example_train.TEXT.values)\n",
    "        test_vect = vect.transform(test_df.TEXT.values)\n",
    "\n",
    "        train_label = example_train[label_column]\n",
    "        test_label = test_df[label_column]\n",
    "\n",
    "        model_xgb = XGBClassifier(subsample = 0.7, n_estimators = 750, max_depth = 48, learning_rate = 0.016, colsample_bytree = 0.8, colsample_bylevel = 0.5, seed = 20)\n",
    "        model_xgb = model_xgb.fit(train_vect, train_label)\n",
    "\n",
    "        predictions = model_xgb.predict_proba(test_vect)\n",
    "\n",
    "        full_metrics.append([EXAMPLES, get_metrics_best_threshold(predictions,test_label)])\n",
    "    trainset_metrics.append([trainset, full_metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cefab4c",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e56eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trainset, full_metrics in trainset_metrics:\n",
    "    print(f\"----------{trainset}----------\")\n",
    "    for example_num, metrics in full_metrics:\n",
    "        print(f\"-----------------------{example_num}---------------------------\")\n",
    "        print(metrics['clss_report'])\n",
    "        print(f\"AUROC: {round(metrics['auroc'],4)}\")\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(metrics[\"confusion_matrix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53777401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
